{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnheU6HveaNcRlMI4vWZwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/player-29/Data-Science-For-Beginners/blob/main/task_1a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5w_PJO1JSAL",
        "outputId": "c8ac822c-f6dd-4afc-b0a6-531d63c5a141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Education  JoiningYear  City  PaymentTier  Age  Gender  EverBenched  \\\n",
            "0             0         2012     0            3   37       1            0   \n",
            "1             1         2017     1            2   28       1            0   \n",
            "2             0         2017     1            2   36       1            0   \n",
            "3             0         2015     0            3   27       1            1   \n",
            "4             0         2017     0            3   29       1            0   \n",
            "...         ...          ...   ...          ...  ...     ...          ...   \n",
            "4628          0         2013     0            3   26       0            0   \n",
            "4629          1         2013     2            2   37       1            0   \n",
            "4630          1         2018     1            3   27       1            0   \n",
            "4631          0         2012     0            3   30       1            1   \n",
            "4632          0         2015     0            3   33       1            1   \n",
            "\n",
            "      ExperienceInCurrentDomain  LeaveOrNot  \n",
            "0                             0           0  \n",
            "1                             4           0  \n",
            "2                             3           0  \n",
            "3                             5           0  \n",
            "4                             4           0  \n",
            "...                         ...         ...  \n",
            "4628                          4           0  \n",
            "4629                          2           1  \n",
            "4630                          5           1  \n",
            "4631                          2           0  \n",
            "4632                          4           0  \n",
            "\n",
            "[4633 rows x 9 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4633 entries, 0 to 4632\n",
            "Data columns (total 8 columns):\n",
            " #   Column                     Non-Null Count  Dtype\n",
            "---  ------                     --------------  -----\n",
            " 0   Education                  4633 non-null   int64\n",
            " 1   JoiningYear                4633 non-null   int64\n",
            " 2   City                       4633 non-null   int64\n",
            " 3   PaymentTier                4633 non-null   int64\n",
            " 4   Age                        4633 non-null   int64\n",
            " 5   Gender                     4633 non-null   int64\n",
            " 6   EverBenched                4633 non-null   int64\n",
            " 7   ExperienceInCurrentDomain  4633 non-null   int64\n",
            "dtypes: int64(8)\n",
            "memory usage: 289.7 KB\n",
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 4633 entries, 0 to 4632\n",
            "Series name: LeaveOrNot\n",
            "Non-Null Count  Dtype\n",
            "--------------  -----\n",
            "4633 non-null   int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 36.3 KB\n",
            "X_train_tensor shape: torch.Size([3706, 8])\n",
            "y_train_tensor shape: torch.Size([3706])\n",
            "X_test_tensor shape: torch.Size([927, 8])\n",
            "y_test_tensor shape: torch.Size([927])\n",
            "train_dataloader: <torch.utils.data.dataloader.DataLoader object at 0x7ddfbe318640>\n",
            "Accuracy on the test set = 0.656502968159741\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder  # or try OneHotEncoder if this doesnt work\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "dataframe= pd.read_csv('/task_1a_dataset.csv')\n",
        "\n",
        "dataframe\n",
        "\n",
        "def data_preprocessing(task_1a_dataframe):\n",
        "    dataset = task_1a_dataframe.copy()\n",
        "    labelencoder = LabelEncoder()\n",
        "    dataset['Education'] = labelencoder.fit_transform(dataset['Education'])\n",
        "    dataset['City'] = labelencoder.fit_transform(dataset['City'])\n",
        "    dataset['Gender'] = labelencoder.fit_transform(dataset['Gender'])\n",
        "    dataset['EverBenched'] = labelencoder.fit_transform(dataset['EverBenched'])\n",
        "    dataset['ExperienceInCurrentDomain'].fillna(dataset['ExperienceInCurrentDomain'].mean(), inplace=True)\n",
        "    dataset['PaymentTier'].fillna(dataset['PaymentTier'].mean(), inplace=True)\n",
        "    dataset['Age'].fillna(dataset['Age'].mean(), inplace=True)\n",
        "    encoded_dataframe = dataset\n",
        "    return encoded_dataframe\n",
        "\n",
        "encoded = data_preprocessing(dataframe)\n",
        "print(encoded)\n",
        "\n",
        "encoded\n",
        "\n",
        "def identify_features_and_targets(encoded_dataframe):\n",
        "    features = encoded_dataframe.iloc[:, :-1]\n",
        "    target = encoded_dataframe.iloc[:, -1]\n",
        "    features_and_targets = [features, target]\n",
        "    return features_and_targets\n",
        "\n",
        "features_and_targets=identify_features_and_targets(encoded)\n",
        "features_and_targets\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_sample = self.X[idx]\n",
        "        y_sample = self.y[idx]\n",
        "        return x_sample, y_sample\n",
        "\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def load__as__tensors(features_and_targets):\n",
        "    features = features_and_targets[0]\n",
        "    target = features_and_targets[1]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
        "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    # Create custom dataset instances for training and testing\n",
        "    train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "    test_dataset = CustomDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "    # Create a DataLoader for training data\n",
        "    batch_size = 64  # Adjust as needed\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    return [X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, train_dataloader]\n",
        "\n",
        "tensors_and_iterable_training_data = load__as__tensors(features_and_targets)\n",
        "tensors_and_iterable_training_data\n",
        "\n",
        "tensors_and_iterable_training_data = load__as__tensors(features_and_targets)\n",
        "tensors_and_iterable_training_data\n",
        "\n",
        "encoded.drop('LeaveOrNot', axis=1).info()\n",
        "\n",
        "encoded['LeaveOrNot'].info()\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "X_train_tensor, X_test_tensor, y_train_tensor,y_test_tensor,train_dataloader = load__as__tensors(features_and_targets)\n",
        "print(\"X_train_tensor shape:\", X_train_tensor.shape)\n",
        "print(\"y_train_tensor shape:\", y_train_tensor.shape)\n",
        "print(\"X_test_tensor shape:\", X_test_tensor.shape)\n",
        "print(\"y_test_tensor shape:\", y_test_tensor.shape)\n",
        "print(\"train_dataloader:\",train_dataloader)\n",
        "\n",
        "class Salary_Predictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Salary_Predictor, self).__init__()\n",
        "        # Define your model architecture here\n",
        "        self.fc1 = torch.nn.Linear(X_train_tensor.shape[1],128)\n",
        "        self.fc2 = torch.nn.Linear(128,1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "model=Salary_Predictor()\n",
        "\n",
        "def model_loss_function(): #can be in-built from pytorch, use binary cross entropy\n",
        "  return nn.BCELoss()\n",
        "\n",
        "loss_function=model_loss_function()\n",
        "\n",
        "import torch.optim as optim\n",
        "def model_optimizer(model):\n",
        "  return torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "optimizer=model_optimizer(model)\n",
        "\n",
        "def model_number_of_epochs():\n",
        "  return 10\n",
        "\n",
        "number_of_epochs=model_number_of_epochs()\n",
        "\n",
        "def training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer):\n",
        "\n",
        "\t# Unpack tensors and iterable training data\n",
        "\tX_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, train_loader = tensors_and_iterable_training_data;y_train_tensor = y_train_tensor.view(-1, 1)   ;y_test_tensor = y_test_tensor.view(-1, 1)\n",
        "\n",
        "\tfor epoch in range(number_of_epochs):\n",
        "\t\tmodel.train()  # Set the model in training mode\n",
        "\n",
        "\t\t# Initialize variables to track loss and accuracy\n",
        "\t\ttotal_loss = 0.0\n",
        "\t\tcorrect_predictions = 0\n",
        "\n",
        "\t\tfor batch_x, batch_y in train_loader:\n",
        "\t\t\t# Zero the gradients\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\t\t# Forward pass\n",
        "\t\t\toutputs = model(batch_x);batch_y=batch_y.view(-1,1)\n",
        "\t\t\t# Calculate loss\n",
        "\t\t\tloss = loss_function(outputs,batch_y)\n",
        "\n",
        "\t\t\t# Backpropagate and update parameters\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()\n",
        "\n",
        "\t\t\t# Accumulate loss\n",
        "\t\t\ttotal_loss += loss.item()\n",
        "\n",
        "\t\t\t# Calculate the number of correct predictions\n",
        "\t\t\t_, predicted = torch.max(outputs, 1)\n",
        "\t\t\tcorrect_predictions += (predicted == batch_y).sum().item()\n",
        "\n",
        "\t\t# Calculate average loss and accuracy for the epoch\n",
        "\t\tavg_loss = total_loss / len(train_loader.dataset)\n",
        "\t\taccuracy = correct_predictions / len(train_loader.dataset)\n",
        "\n",
        "\t\t# # Print training progress\n",
        "\n",
        "\treturn model\n",
        "\n",
        "def validation_function(trained_model, tensors_and_iterable_training_data):\n",
        "\n",
        "\t # Unpack tensors and validation data loader\n",
        "\tX_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, test_loader = tensors_and_iterable_training_data\n",
        "\n",
        "\ttrained_model.eval()  # Set the model in evaluation mode\n",
        "\n",
        "\tcorrect_predictions = 0\n",
        "\ttotal_examples = 0\n",
        "\n",
        "\twith torch.no_grad():  # Disable gradient computation for validation\n",
        "\t\tfor batch_x, batch_y in test_loader:\n",
        "\t\t\t# Forward pass to make predictions\n",
        "\t\t\toutputs = trained_model(batch_x)\n",
        "\n",
        "\n",
        "\t\t\t# Calculate the number of correct predictions\n",
        "\t\t\t_, predicted = torch.max(outputs, 1)\n",
        "\t\t\tcorrect_predictions += (predicted == batch_y).sum().item()\n",
        "\t\t\ttotal_examples += batch_y.size(0)\n",
        "\n",
        "\t# Calculate the accuracy\n",
        "\tmodel_accuracy = correct_predictions / total_examples\n",
        "\n",
        "\n",
        "\treturn model_accuracy\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # reading the provided dataset csv file using pandas library and\n",
        "    # converting it to a pandas Dataframe\n",
        "    task_1a_dataframe = pd.read_csv('/task_1a_dataset.csv')\n",
        "\n",
        "\n",
        "    # data preprocessing and obtaining encoded data\n",
        "    encoded_dataframe = data_preprocessing(task_1a_dataframe)\n",
        "\n",
        "    # selecting required features and targets\n",
        "    features_and_targets = identify_features_and_targets(encoded_dataframe)\n",
        "\n",
        "\n",
        "    tensors_and_iterable_training_data = load__as__tensors(features_and_targets)\n",
        "    # model is an instance of the class that defines the architecture of the model\n",
        "    model = Salary_Predictor()\n",
        "\n",
        "    # obtaining loss function, optimizer and the number of training epochs\n",
        "    loss_function = model_loss_function()\n",
        "    optimizer = model_optimizer(model)\n",
        "    number_of_epochs = model_number_of_epochs()\n",
        "\n",
        "    # training the model\n",
        "\n",
        "    trained_model = training_function(model, number_of_epochs, tensors_and_iterable_training_data,\n",
        "                    loss_function, optimizer)\n",
        "\n",
        "    # validating and obtaining accuracy\n",
        "    model_accuracy = validation_function(trained_model,tensors_and_iterable_training_data)\n",
        "    print(f\"Accuracy on the test set = {model_accuracy}\")\n",
        "\n",
        "    X_train_tensor = tensors_and_iterable_training_data[0]\n",
        "    x = X_train_tensor[0]\n",
        "    jitted_model = torch.jit.save(torch.jit.trace(model, (x)), \"task_1a_trained_model.pth\")"
      ]
    }
  ]
}